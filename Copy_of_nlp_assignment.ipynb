{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of nlp-assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization Functions"
      ],
      "metadata": {
        "id": "vpM2anIVHdyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "l6UAjY3KIWkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "aKyE5xmBKcJQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "gghLg13PHjN-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I'm Soundhiri. I'm Studying B.E CSE...\"\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "print(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDoispvQH0Vi",
        "outputId": "0befd1ba-f064-4249-9e58-fabfbfca2d36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', \"'m\", 'Soundhiri.', 'I', \"'m\", 'Studying', 'B.E', 'CSE', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. WordPunct Tokenizer"
      ],
      "metadata": {
        "id": "aSsQek0kIYW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "5cVWARO_Idsa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wordpunct_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWOuA_6IIlo3",
        "outputId": "a327b7b1-d6ea-431d-86e3-3321bfb14b38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', \"'\", 'm', 'Soundhiri', '.', 'I', \"'\", 'm', 'Studying', 'B', '.', 'E', 'CSE', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. MWE Tokenizer"
      ],
      "metadata": {
        "id": "JZgGLbH-IzO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "V7DYvi5KI2sr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKR4AHKkKO35",
        "outputId": "364228d4-da9d-4db1-a014-2b49301bcfa0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokeniz = MWETokenizer()\n",
        "tokeniz.add_mwe(('B.E','CSE'))\n",
        "print(tokeniz.tokenize(word_tokenize(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ljlm8x3I5Yc",
        "outputId": "ec1f07dd-58ae-49bb-9544-e4d334cc631a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', \"'m\", 'Soundhiri', '.', 'I', \"'m\", 'Studying', 'B.E_CSE', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Stemming  examples"
      ],
      "metadata": {
        "id": "TeScBx2PL6Lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Lancaster Stemming"
      ],
      "metadata": {
        "id": "gimIV3WuL9IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer"
      ],
      "metadata": {
        "id": "mixkIKk8L_9q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lancaster = LancasterStemmer()\n",
        "words = ['drinking','drink','drank','eat','eating']\n",
        "for word in words:\n",
        "    print(word,\"--->\",lancaster.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlFROv9zMTyj",
        "outputId": "146575a1-6af6-44a3-9e51-fc23925acd99"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drinking ---> drink\n",
            "drink ---> drink\n",
            "drank ---> drank\n",
            "eat ---> eat\n",
            "eating ---> eat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Regexp Stemmer"
      ],
      "metadata": {
        "id": "ZUDUgE0nMzGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "wvhj95VnM3ju"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "words = ['massable','was','bees','computers','advisable']\n",
        "for word in words:\n",
        "    print(word,\"--->\",regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA8N87MwM9Ww",
        "outputId": "969498cf-099e-4855-983d-64eaa668c7b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "massable ---> mass\n",
            "was ---> was\n",
            "bees ---> bee\n",
            "computers ---> computer\n",
            "advisable ---> advis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization techniques"
      ],
      "metadata": {
        "id": "CkfDm1o7NP8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. spaCy Lemmatization"
      ],
      "metadata": {
        "id": "Ysts0gR2OUBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "7eMaugaBNybL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(u'the bats saw the cats with best stripes hanging upside down by their feet')\n",
        "tokens = []\n",
        "for token in doc:\n",
        "    tokens.append(token)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST15PN4uOdZJ",
        "outputId": "d86ad4af-dfe1-414a-db2c-63acfc023d73"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[the, bats, saw, the, cats, with, best, stripes, hanging, upside, down, by, their, feet]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_sentence = \" \".join([token.lemma_ for token in doc])\n",
        "print(lemmatized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZuX1JYVOqw7",
        "outputId": "22535c43-4663-4bbd-bf0c-d7cab9dbd315"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bat see the cat with good stripe hang upside down by -PRON- foot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. TreeTagger Lemmatization"
      ],
      "metadata": {
        "id": "KDUMgwGCOxYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pattern\n",
        "import pattern\n",
        "from pattern.en import lemma, lexeme\n",
        "from pattern.en import parse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJY0j4eJO1RA",
        "outputId": "aba4b3a1-cf2d-4b87-d0d0-1a030e5480b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pattern) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.1.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pattern) (4.2.6)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20220319-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 27.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pattern) (3.2.5)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 29.1 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pattern) (2.23.0)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 63.9 MB/s \n",
            "\u001b[?25hCollecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.5.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern) (8.12.0)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.15.0)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.5.0-py3-none-any.whl (7.0 kB)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.0.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.1)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.7.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.1.1-py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern) (3.8.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (3.0.4)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-37.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 34.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->pattern) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern) (2.21)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2021.10.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->pattern) (57.4.0)\n",
            "Building wheels for collected packages: pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332721 sha256=9847b49b36e14d026a8937643a133f9e9411ff3a11d43871f0da2d004aeb934e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/1f/4e/9b67afd2430d55dee90bd57618dd7d899f1323e5852c465682\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.0-cp37-cp37m-linux_x86_64.whl size=99970 sha256=d7d22e14ee8e9302f4eb46fe9765056fd4f33bddc8f7e66387523596806867b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/d4/df/08cd6e1fa4a8691b268ab254bd0fa589827ab5b65638c010b4\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=4adfefef540c5f37fb67422654495f4e4d26617d168935a6b226aa513979bb41\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=1318aec18c0b57f2308ac0bbfac35b37993d8ecef8a550745db0045ad37405ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: jaraco.functools, jaraco.context, tempora, jaraco.text, jaraco.classes, zc.lockfile, sgmllib3k, portend, jaraco.collections, cryptography, cheroot, python-docx, pdfminer.six, mysqlclient, feedparser, cherrypy, backports.csv, pattern\n",
            "Successfully installed backports.csv-1.0.7 cheroot-8.6.0 cherrypy-18.6.1 cryptography-37.0.0 feedparser-6.0.8 jaraco.classes-3.2.1 jaraco.collections-3.5.1 jaraco.context-4.1.1 jaraco.functools-3.5.0 jaraco.text-3.7.0 mysqlclient-2.1.0 pattern-3.6 pdfminer.six-20220319 portend-3.1.0 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-5.0.1 zc.lockfile-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"the bats saw the cats with best stripes hanging upside down by their feet\"\n",
        "lemmatized_sentence = \" \".join([lemma(word) for word in sentence.split()])\n",
        "print(lemmatized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnC5UGksQX03",
        "outputId": "6da67bc3-32bd-407d-8332-5ad2a65538e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bat see the cat with best stripe hang upside down by their feet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_lemmas_for_each_word = [lexeme(wd) for wd in sentence.split()]\n",
        "print(all_lemmas_for_each_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ds-LLv3ROso",
        "outputId": "a570854d-f1ed-4ff9-f866-f0567b715914"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['the', 'thes', 'thing', 'thed'], ['bat', 'bats', 'batting', 'batted'], ['see', 'sees', 'seeing', 'saw', 'seen'], ['the', 'thes', 'thing', 'thed'], ['cat', 'cats', 'catting', 'catted'], ['with', 'withs', 'withing', 'withed'], ['best', 'bests', 'besting', 'bested'], ['stripe', 'stripes', 'striping', 'striped'], ['hang', 'hangs', 'hanging', 'hung'], ['upside', 'upsides', 'upsiding', 'upsided'], ['down', 'downs', 'downing', 'downed'], ['by', 'bies', 'bying', 'bied'], ['their', 'theirs', 'theiring', 'theired'], ['feet', 'feets', 'feeting', 'feeted']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Genism"
      ],
      "metadata": {
        "id": "O4SuRDeuRRGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import lemmatize"
      ],
      "metadata": {
        "id": "bk_b8uYNRXrA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"the bats saw the cats with best stripes hanging upside down by their feet\"\n",
        " \n",
        "lemmatized_sentence = [word.decode('utf-8').split('.')[0] for word in lemmatize(sentence)]\n",
        " \n",
        "print(lemmatized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO8QKl84RbS3",
        "outputId": "6839b701-ccbc-4518-a6b7-fa0cc4614813"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bat/NN', 'see/VB', 'cat/NN', 'best/JJ', 'stripe/NN', 'hang/VB', 'upside/RB', 'foot/NN']\n"
          ]
        }
      ]
    }
  ]
}